question,answer,retrieved_docs,retrieved_titles,retrieved_terms,similarities
What does deep reinforcement learning combine?,model-free and model-based deep reinforcement learning algorithms,"['Deep reinforcement learning enables algorithms to learn complex behavior,\r\ndeal with continuous action spaces and find good strategies in environments\r\nwith high dimensional state spaces. With deep reinforcement learning being an\r\nactive area of research and many concurrent inventions, we decided to focus on\r\na relatively simple robotic task to evaluate a set of ideas that might help to\r\nsolve recent reinforcement learning problems. We test a newly created\r\ncombination of two commonly used reinforcement learning methods, whether it is\r\nable to learn more effectively than a baseline. We also compare different ideas\r\nto preprocess information before it is fed to the reinforcement learning\r\nalgorithm. The goal of this strategy is to reduce training time and eventually\r\nhelp the algorithm to converge. The concluding evaluation proves the general\r\napplicability of the described concepts by testing them using a simulated\r\nenvironment. These concepts might be reused for future experiments.', 'Learning robust value functions given raw observations and rewards is now\r\npossible with model-free and model-based deep reinforcement learning\r\nalgorithms. There is a third alternative, called Successor Representations\r\n(SR), which decomposes the value function into two components -- a reward\r\npredictor and a successor map. The successor map represents the expected future\r\nstate occupancy from any given state and the reward predictor maps states to\r\nscalar rewards. The value function of a state can be computed as the inner\r\nproduct between the successor map and the reward weights. In this paper, we\r\npresent DSR, which generalizes SR within an end-to-end deep reinforcement\r\nlearning framework. DSR has several appealing properties including: increased\r\nsensitivity to distal reward changes due to factorization of reward and world\r\ndynamics, and the ability to extract bottleneck states (subgoals) given\r\nsuccessor maps trained under a random policy. We show the efficacy of our\r\napproach on two diverse environments given raw pixel observations -- simple\r\ngrid-world domains (MazeBase) and the Doom game engine.', ""The ability to transfer skills across tasks has the potential to scale up\r\nreinforcement learning (RL) agents to environments currently out of reach.\r\nRecently, a framework based on two ideas, successor features (SFs) and\r\ngeneralised policy improvement (GPI), has been introduced as a principled way\r\nof transferring skills. In this paper we extend the SFs & GPI framework in two\r\nways. One of the basic assumptions underlying the original formulation of SFs &\r\nGPI is that rewards for all tasks of interest can be computed as linear\r\ncombinations of a fixed set of features. We relax this constraint and show that\r\nthe theoretical guarantees supporting the framework can be extended to any set\r\nof tasks that only differ in the reward function. Our second contribution is to\r\nshow that one can use the reward functions themselves as features for future\r\ntasks, without any loss of expressiveness, thus removing the need to specify a\r\nset of features beforehand. This makes it possible to combine SFs & GPI with\r\ndeep learning in a more stable way. We empirically verify this claim on a\r\ncomplex 3D environment where observations are images from a first-person\r\nperspective. We show that the transfer promoted by SFs & GPI leads to very good\r\npolicies on unseen tasks almost instantaneously. We also describe how to learn\r\npolicies specialised to the new tasks in a way that allows them to be added to\r\nthe agent's set of skills, and thus be reused in the future.""]","['Using Deep Reinforcement Learning for the Continuous Control of Robotic Arms', 'Deep Successor Reinforcement Learning', 'Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement']","[['cs.LG', 'cs.RO', 'stat.ML'], ['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE'], ['cs.LG', 'cs.AI']]","[0.8838365077972412, 0.8750435709953308, 0.8743285536766052]"
What is the main focus of the research in this paper regarding Blockchain technologies?,Reverse Vending Machines,"['This work proposes DeepFolio, a new model for deep portfolio management based\r\non data from limit order books (LOB). DeepFolio solves problems found in the\r\nstate-of-the-art for LOB data to predict price movements. Our evaluation\r\nconsists of two scenarios using a large dataset of millions of time series. The\r\nimprovements deliver superior results both in cases of abundant as well as\r\nscarce data. The experiments show that DeepFolio outperforms the\r\nstate-of-the-art on the benchmark FI-2010 LOB. Further, we use DeepFolio for\r\noptimal portfolio allocation of crypto-assets with rebalancing. For this\r\npurpose, we use two loss-functions - Sharpe ratio loss and minimum volatility\r\nrisk. We show that DeepFolio outperforms widely used portfolio allocation\r\ntechniques in the literature.', 'Reverse Vending Machines (RVMs) are a proven instrument for facilitating\r\nclosed-loop plastic packaging recycling. A good customer experience at the RVM\r\nis crucial for a further proliferation of this technology. Bin full events are\r\nthe major reason for Reverse Vending Machine (RVM) downtime at the world leader\r\nin the RVM market. The paper at hand develops and evaluates an approach based\r\non machine learning and statistical approximation to foresee bin full events\r\nand, thus increase uptime of RVMs. Our approach relies on forecasting the\r\nhourly time series of returned beverage containers at a given RVM. We\r\ncontribute by developing and evaluating an approach for hourly forecasts in a\r\nretail setting - this combination of application domain and forecast\r\ngranularity is novel. A trace-driven simulation confirms that the\r\nforecasting-based approach leads to less downtime and costs than naive emptying\r\nstrategies.', ""Advances in renewable energy generation and introduction of the government\r\ntargets to improve energy efficiency gave rise to a concept of a Zero Energy\r\nBuilding (ZEB). A ZEB is a building whose net energy usage over a year is zero,\r\ni.e., its energy use is not larger than its overall renewables generation. A\r\ncollection of ZEBs forms a Zero Energy Community (ZEC). This paper addresses\r\nthe problem of energy sharing in such a community. This is different from\r\npreviously addressed energy sharing between buildings as our focus is on the\r\nimprovement of community energy status, while traditionally research focused on\r\nreducing losses due to transmission and storage, or achieving economic gains.\r\nWe model this problem in a multi-agent environment and propose a Deep\r\nReinforcement Learning (DRL) based solution. Each building is represented by an\r\nintelligent agent that learns over time the appropriate behaviour to share\r\nenergy. We have evaluated the proposed solution in a multi-agent simulation\r\nbuilt using osBrain. Results indicate that with time agents learn to\r\ncollaborate and learn a policy comparable to the optimal policy, which in turn\r\nimproves the ZEC's energy status. Buildings with no renewables preferred to\r\nrequest energy from their neighbours rather than from the supply grid.""]","['DeepFolio: Convolutional Neural Networks for Portfolios with Limit Order Book Data', 'Half-empty or half-full? A Hybrid Approach to Predict Recycling Behavior of Consumers to Increase Reverse Vending Machine Uptime', 'Multi-agent Deep Reinforcement Learning for Zero Energy Communities']","[['cs.LG', 'q-fin.TR', 'stat.AP', 'stat.ML'], ['cs.LG', 'stat.AP', 'stat.ML'], ['cs.LG', 'cs.AI', 'cs.MA', 'stat.ML', '97R40', 'I.2.11; I.2.6']]","[0.8250530362129211, 0.8182891607284546, 0.8095579147338867]"
What does pose information represent in Capsule Networks?,a generative 3D part assembly,"['Autonomous part assembly is a challenging yet crucial task in 3D computer\r\nvision and robotics. Analogous to buying an IKEA furniture, given a set of 3D\r\nparts that can assemble a single shape, an intelligent agent needs to perceive\r\nthe 3D part geometry, reason to propose pose estimations for the input parts,\r\nand finally call robotic planning and control routines for actuation. In this\r\npaper, we focus on the pose estimation subproblem from the vision side\r\ninvolving geometric and relational reasoning over the input part geometry.\r\nEssentially, the task of generative 3D part assembly is to predict a 6-DoF part\r\npose, including a rigid rotation and translation, for each input part that\r\nassembles a single 3D shape as the final output. To tackle this problem, we\r\npropose an assembly-oriented dynamic graph learning framework that leverages an\r\niterative graph neural network as a backbone. It explicitly conducts sequential\r\npart assembly refinements in a coarse-to-fine manner, exploits a pair of part\r\nrelation reasoning module and part aggregation module for dynamically adjusting\r\nboth part features and their relations in the part graph. We conduct extensive\r\nexperiments and quantitative comparisons to three strong baseline methods,\r\ndemonstrating the effectiveness of the proposed approach.', 'The task of estimating the 6D pose of an object from RGB images can be broken\r\ndown into two main steps: an initial pose estimation step, followed by a\r\nrefinement procedure to correctly register the object and its observation. In\r\nthis paper, we propose a new method for 6D pose estimation refinement from RGB\r\nimages. To achieve high accuracy of the final estimate, the observation and a\r\nrendered model need to be aligned. Our main insight is that after the initial\r\npose estimate, it is important to pay attention to distinct spatial features of\r\nthe object in order to improve the estimation accuracy during alignment.\r\nFurthermore, parts of the object that are occluded in the image should be given\r\nless weight during the alignment process. Most state-of-the-art refinement\r\napproaches do not allow for this fine-grained reasoning and can not fully\r\nleverage the structure of the problem. In contrast, we propose a novel neural\r\nnetwork architecture built around a spatial attention mechanism that identifies\r\nand leverages information about spatial details during pose refinement. We\r\nexperimentally show that this approach learns to attend to salient spatial\r\nfeatures and learns to ignore occluded parts of the object, leading to better\r\npose estimation across datasets. We conduct experiments on standard benchmark\r\ndatasets for 6D pose estimation (LineMOD and Occlusion LineMOD) and outperform\r\nprevious state-of-the-art methods.', 'Autonomous assembly of objects is an essential task in robotics and 3D\r\ncomputer vision. It has been studied extensively in robotics as a problem of\r\nmotion planning, actuator control and obstacle avoidance. However, the task of\r\ndeveloping a generalized framework for assembly robust to structural variants\r\nremains relatively unexplored. In this work, we tackle this problem using a\r\nrecurrent graph learning framework considering inter-part relations and the\r\nprogressive update of the part pose. Our network can learn more plausible\r\npredictions of shape structure by accounting for priorly assembled parts.\r\nCompared to the current state-of-the-art, our network yields up to 10%\r\nimprovement in part accuracy and up to 15% improvement in connectivity accuracy\r\non the PartNet dataset. Moreover, our resulting latent space facilitates\r\nexciting applications such as shape recovery from the point-cloud components.\r\nWe conduct extensive experiments to justify our design choices and demonstrate\r\nthe effectiveness of the proposed framework.']","['Generative 3D Part Assembly via Dynamic Graph Learning', 'Spatial Attention Improves Iterative 6D Object Pose Estimation', 'RGL-NET: A Recurrent Graph Learning framework for Progressive Part Assembly']","[['cs.CV'], ['cs.CV'], ['cs.CV']]","[0.8771266937255859, 0.8765556812286377, 0.8759101033210754]"
What are the key components of VA-GAN?,a novel measure of performance of a GAN,"['Evaluating generative adversarial networks (GANs) is inherently challenging.\r\nIn this paper, we revisit several representative sample-based evaluation\r\nmetrics for GANs, and address the problem of how to evaluate the evaluation\r\nmetrics. We start with a few necessary conditions for metrics to produce\r\nmeaningful scores, such as distinguishing real from generated samples,\r\nidentifying mode dropping and mode collapsing, and detecting overfitting. With\r\na series of carefully designed experiments, we comprehensively investigate\r\nexisting sample-based metrics and identify their strengths and limitations in\r\npractical settings. Based on these results, we observe that kernel Maximum Mean\r\nDiscrepancy (MMD) and the 1-Nearest-Neighbor (1-NN) two-sample test seem to\r\nsatisfy most of the desirable properties, provided that the distances between\r\nsamples are computed in a suitable feature space. Our experiments also unveil\r\ninteresting properties about the behavior of several popular GAN models, such\r\nas whether they are memorizing training samples, and how far they are from\r\nlearning the target distribution.', 'One of the biggest challenges in the research of generative adversarial\r\nnetworks (GANs) is assessing the quality of generated samples and detecting\r\nvarious levels of mode collapse. In this work, we construct a novel measure of\r\nperformance of a GAN by comparing geometrical properties of the underlying data\r\nmanifold and the generated one, which provides both qualitative and\r\nquantitative means for evaluation. Our algorithm can be applied to datasets of\r\nan arbitrary nature and is not limited to visual data. We test the obtained\r\nmetric on various real-life models and datasets and demonstrate that our method\r\nprovides new insights into properties of GANs.', 'Inferring the latent variable generating a given test sample is a challenging\r\nproblem in Generative Adversarial Networks (GANs). In this paper, we propose\r\nInvGAN - a novel framework for solving the inference problem in GANs, which\r\ninvolves training an encoder network capable of inverting a pre-trained\r\ngenerator network without access to any training data. Under mild assumptions,\r\nwe theoretically show that using InvGAN, we can approximately invert the\r\ngenerations of any latent code of a trained GAN model. Furthermore, we\r\nempirically demonstrate the superiority of our inference scheme by quantitative\r\nand qualitative comparisons with other methods that perform a similar task. We\r\nalso show the effectiveness of our framework in the problem of adversarial\r\ndefenses where InvGAN can successfully be used as a projection-based defense\r\nmechanism. Additionally, we show how InvGAN can be used to implement\r\nreparameterization white-box attacks on projection-based defense mechanisms.\r\nExperimental validation on several benchmark datasets demonstrate the efficacy\r\nof our method in achieving improved performance on several white-box and\r\nblack-box attacks. Our code is available at\r\nhttps://github.com/yogeshbalaji/InvGAN.']","['An empirical study on evaluation metrics of generative adversarial networks', 'Geometry Score: A Method For Comparing Generative Adversarial Networks', 'Invert and Defend: Model-based Approximate Inversion of Generative Adversarial Networks for Secure Inference']","[['cs.LG', 'cs.CV', 'stat.ML'], ['cs.LG', 'cs.CG', 'stat.ML'], ['cs.LG', 'cs.CV', 'stat.ML']]","[0.8546629548072815, 0.8514755368232727, 0.8501788973808289]"
How does the paper contribute to understanding the network dynamics behind cryptocurrencies like Bitcoin?,chemoinformatics,"['This work proposes DeepFolio, a new model for deep portfolio management based\r\non data from limit order books (LOB). DeepFolio solves problems found in the\r\nstate-of-the-art for LOB data to predict price movements. Our evaluation\r\nconsists of two scenarios using a large dataset of millions of time series. The\r\nimprovements deliver superior results both in cases of abundant as well as\r\nscarce data. The experiments show that DeepFolio outperforms the\r\nstate-of-the-art on the benchmark FI-2010 LOB. Further, we use DeepFolio for\r\noptimal portfolio allocation of crypto-assets with rebalancing. For this\r\npurpose, we use two loss-functions - Sharpe ratio loss and minimum volatility\r\nrisk. We show that DeepFolio outperforms widely used portfolio allocation\r\ntechniques in the literature.', ""Several social, medical, engineering and biological challenges rely on\r\ndiscovering the functionality of networks from their structure and node\r\nmetadata, when it is available. For example, in chemoinformatics one might want\r\nto detect whether a molecule is toxic based on structure and atomic types, or\r\ndiscover the research field of a scientific collaboration network. Existing\r\ntechniques rely on counting or measuring structural patterns that are known to\r\nshow large variations from network to network, such as the number of triangles,\r\nor the assortativity of node metadata. We introduce the concept of multi-hop\r\nassortativity, that captures the similarity of the nodes situated at the\r\nextremities of a randomly selected path of a given length. We show that\r\nmulti-hop assortativity unifies various existing concepts and offers a\r\nversatile family of 'fingerprints' to characterize networks. These fingerprints\r\nallow in turn to recover the functionalities of a network, with the help of the\r\nmachine learning toolbox. Our method is evaluated empirically on established\r\nsocial and chemoinformatic network benchmarks. Results reveal that our\r\nassortativity based features are competitive providing highly accurate results\r\noften outperforming state of the art methods for the network classification\r\ntask."", 'This work derives closed-form expressions computing the expectation of\r\nco-presence and of number of co-occurrences of nodes on paths sampled from a\r\nnetwork according to general path weights (a bag of paths). The underlying idea\r\nis that two nodes are considered as similar when they often appear together on\r\n(preferably short) paths of the network. The different expressions are obtained\r\nfor both regular and hitting paths and serve as a basis for computing new\r\ncovariance and correlation measures between nodes, which are valid positive\r\nsemi-definite kernels on a graph. Experiments on semi-supervised classification\r\nproblems show that the introduced similarity measures provide competitive\r\nresults compared to other state-of-the-art distance and similarity measures\r\nbetween nodes.']","['DeepFolio: Convolutional Neural Networks for Portfolios with Limit Order Book Data', 'Multi-hop assortativities for networks classification', 'Covariance and Correlation Kernels on a Graph in the Generalized Bag-of-Paths Formalism']","[['cs.LG', 'q-fin.TR', 'stat.AP', 'stat.ML'], ['cs.LG', 'cs.SI', 'stat.ML'], ['cs.LG', 'stat.ML']]","[0.8535720109939575, 0.8420456647872925, 0.8328180313110352]"
What specific image processing algorithms were used to transform RNA sequences into gene motifs for the CNN classification?,A multi-task learning method to relax the constraint of segmentation,"['Fully supervised deep neural networks for segmentation usually require a\r\nmassive amount of pixel-level labels which are manually expensive to create. In\r\nthis work, we develop a multi-task learning method to relax this constraint. We\r\nregard the segmentation problem as a sequence of approximation subproblems that\r\nare recursively defined and in increasing levels of approximation accuracy. The\r\nsubproblems are handled by a framework that consists of 1) a segmentation task\r\nthat learns from pixel-level ground truth segmentation masks of a small\r\nfraction of the images, 2) a recursive approximation task that conducts partial\r\nobject regions learning and data-driven mask evolution starting from partial\r\nmasks of each object instance, and 3) other problem oriented auxiliary tasks\r\nthat are trained with sparse annotations and promote the learning of dedicated\r\nfeatures. Most training images are only labeled by (rough) partial masks, which\r\ndo not contain exact object boundaries, rather than by their full segmentation\r\nmasks. During the training phase, the approximation task learns the statistics\r\nof these partial masks, and the partial regions are recursively increased\r\ntowards object boundaries aided by the learned information from the\r\nsegmentation task in a fully data-driven fashion. The network is trained on an\r\nextremely small amount of precisely segmented images and a large set of coarse\r\nlabels. Annotations can thus be obtained in a cheap way. We demonstrate the\r\nefficiency of our approach in three applications with microscopy images and\r\nultrasound images.', 'We introduce language-driven image generation, the task of generating an\r\nimage visualizing the semantic contents of a word embedding, e.g., given the\r\nword embedding of grasshopper, we generate a natural image of a grasshopper. We\r\nimplement a simple method based on two mapping functions. The first takes as\r\ninput a word embedding (as produced, e.g., by the word2vec toolkit) and maps it\r\nonto a high-level visual space (e.g., the space defined by one of the top\r\nlayers of a Convolutional Neural Network). The second function maps this\r\nabstract visual representation to pixel space, in order to generate the target\r\nimage. Several user studies suggest that the current system produces images\r\nthat capture general visual properties of the concepts encoded in the word\r\nembedding, such as color or typical environment, and are sufficient to\r\ndiscriminate between general categories of objects.', 'Here we introduce a new model of natural textures based on the feature spaces\r\nof convolutional neural networks optimised for object recognition. Samples from\r\nthe model are of high perceptual quality demonstrating the generative power of\r\nneural networks trained in a purely discriminative fashion. Within the model,\r\ntextures are represented by the correlations between feature maps in several\r\nlayers of the network. We show that across layers the texture representations\r\nincreasingly capture the statistical properties of natural images while making\r\nobject information more and more explicit. The model provides a new tool to\r\ngenerate stimuli for neuroscience and might offer insights into the deep\r\nrepresentations learned by convolutional neural networks.']","['Multi-task deep learning for image segmentation using recursive approximation tasks', 'Unveiling the Dreams of Word Embeddings: Towards Language-Driven Image Generation', 'Texture Synthesis Using Convolutional Neural Networks']","[['cs.CV', 'cs.LG', 'eess.IV'], ['cs.CV', 'cs.CL'], ['cs.CV', 'cs.NE', 'q-bio.NC']]","[0.881878674030304, 0.8809811472892761, 0.8807882070541382]"
What is the role of camera-aware domain adaptation in the proposed method?,uncertainty-aware domain adaptation network,"['Although various image-based domain adaptation (DA) techniques have been\r\nproposed in recent years, domain shift in videos is still not well-explored.\r\nMost previous works only evaluate performance on small-scale datasets which are\r\nsaturated. Therefore, we first propose a larger-scale dataset with larger\r\ndomain discrepancy: UCF-HMDB_full. Second, we investigate different DA\r\nintegration methods for videos, and show that simultaneously aligning and\r\nlearning temporal dynamics achieves effective alignment even without\r\nsophisticated DA methods. Finally, we propose Temporal Attentive Adversarial\r\nAdaptation Network (TA3N), which explicitly attends to the temporal dynamics\r\nusing domain discrepancy for more effective domain alignment, achieving\r\nstate-of-the-art performance on three video DA datasets. The code and data are\r\nreleased at http://github.com/cmhungsteve/TA3N.', 'Unsupervised domain adaptive object detection aims to adapt detectors from a\r\nlabelled source domain to an unlabelled target domain. Most existing works take\r\na two-stage strategy that first generates region proposals and then detects\r\nobjects of interest, where adversarial learning is widely adopted to mitigate\r\nthe inter-domain discrepancy in both stages. However, adversarial learning may\r\nimpair the alignment of well-aligned samples as it merely aligns the global\r\ndistributions across domains. To address this issue, we design an\r\nuncertainty-aware domain adaptation network (UaDAN) that introduces conditional\r\nadversarial learning to align well-aligned and poorly-aligned samples\r\nseparately in different manners. Specifically, we design an uncertainty metric\r\nthat assesses the alignment of each sample and adjusts the strength of\r\nadversarial learning for well-aligned and poorly-aligned samples adaptively. In\r\naddition, we exploit the uncertainty metric to achieve curriculum learning that\r\nfirst performs easier image-level alignment and then more difficult\r\ninstance-level alignment progressively. Extensive experiments over four\r\nchallenging domain adaptive object detection datasets show that UaDAN achieves\r\nsuperior performance as compared with state-of-the-art methods.', 'Deep networks have been successfully applied to learn transferable features\r\nfor adapting models from a source domain to a different target domain. In this\r\npaper, we present joint adaptation networks (JAN), which learn a transfer\r\nnetwork by aligning the joint distributions of multiple domain-specific layers\r\nacross domains based on a joint maximum mean discrepancy (JMMD) criterion.\r\nAdversarial training strategy is adopted to maximize JMMD such that the\r\ndistributions of the source and target domains are made more distinguishable.\r\nLearning can be performed by stochastic gradient descent with the gradients\r\ncomputed by back-propagation in linear-time. Experiments testify that our model\r\nyields state of the art results on standard datasets.']","['Temporal Attentive Alignment for Video Domain Adaptation', 'Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection', 'Deep Transfer Learning with Joint Adaptation Networks']","[['cs.CV', 'cs.LG', 'cs.MM'], ['cs.CV'], ['cs.LG', 'stat.ML']]","[0.9129962921142578, 0.9045946598052979, 0.9000077247619629]"
What is the primary goal of the Structure Transfer Machine (STM) method?,facilitating closed-loop plastic packaging recycling,"['Autonomous assembly of objects is an essential task in robotics and 3D\r\ncomputer vision. It has been studied extensively in robotics as a problem of\r\nmotion planning, actuator control and obstacle avoidance. However, the task of\r\ndeveloping a generalized framework for assembly robust to structural variants\r\nremains relatively unexplored. In this work, we tackle this problem using a\r\nrecurrent graph learning framework considering inter-part relations and the\r\nprogressive update of the part pose. Our network can learn more plausible\r\npredictions of shape structure by accounting for priorly assembled parts.\r\nCompared to the current state-of-the-art, our network yields up to 10%\r\nimprovement in part accuracy and up to 15% improvement in connectivity accuracy\r\non the PartNet dataset. Moreover, our resulting latent space facilitates\r\nexciting applications such as shape recovery from the point-cloud components.\r\nWe conduct extensive experiments to justify our design choices and demonstrate\r\nthe effectiveness of the proposed framework.', 'Reverse Vending Machines (RVMs) are a proven instrument for facilitating\r\nclosed-loop plastic packaging recycling. A good customer experience at the RVM\r\nis crucial for a further proliferation of this technology. Bin full events are\r\nthe major reason for Reverse Vending Machine (RVM) downtime at the world leader\r\nin the RVM market. The paper at hand develops and evaluates an approach based\r\non machine learning and statistical approximation to foresee bin full events\r\nand, thus increase uptime of RVMs. Our approach relies on forecasting the\r\nhourly time series of returned beverage containers at a given RVM. We\r\ncontribute by developing and evaluating an approach for hourly forecasts in a\r\nretail setting - this combination of application domain and forecast\r\ngranularity is novel. A trace-driven simulation confirms that the\r\nforecasting-based approach leads to less downtime and costs than naive emptying\r\nstrategies.', ""In this work, we study the transfer learning problem under high-dimensional\r\ngeneralized linear models (GLMs), which aim to improve the fit on target data\r\nby borrowing information from useful source data. Given which sources to\r\ntransfer, we propose an oracle algorithm and derive its $\\ell_2$-estimation\r\nerror bounds. The theoretical analysis shows that under certain conditions,\r\nwhen the target and source are sufficiently close to each other, the estimation\r\nerror bound could be improved over that of the classical penalized estimator\r\nusing only target data. When we don't know which sources to transfer, an\r\nalgorithm-free transferable source detection approach is introduced to detect\r\ninformative sources. The detection consistency is proved under the\r\nhigh-dimensional GLM transfer learning setting. Extensive simulations and a\r\nreal-data experiment verify the effectiveness of our algorithms.""]","['RGL-NET: A Recurrent Graph Learning framework for Progressive Part Assembly', 'Half-empty or half-full? A Hybrid Approach to Predict Recycling Behavior of Consumers to Increase Reverse Vending Machine Uptime', 'Transfer Learning under High-dimensional Generalized Linear Models']","[['cs.CV'], ['cs.LG', 'stat.AP', 'stat.ML'], ['stat.ML', 'cs.LG', 'stat.ME']]","[0.8291782736778259, 0.8281556963920593, 0.8259708285331726]"
What is the role of the manifold structure in STM?,Orientation,"['Density estimation is an important technique for characterizing distributions\r\ngiven observations. Much existing research on density estimation has focused on\r\ncases wherein the data lies in a Euclidean space. However, some kinds of data\r\nare not well-modeled by supposing that their underlying geometry is Euclidean.\r\nInstead, it can be useful to model such data as lying on a {\\it manifold} with\r\nsome known structure. For instance, some kinds of data may be known to lie on\r\nthe surface of a sphere. We study the problem of estimating densities on\r\nmanifolds. We propose a method, inspired by the literature on ""dequantization,""\r\nwhich we interpret through the lens of a coordinate transformation of an\r\nambient Euclidean space and a smooth manifold of interest. Using methods from\r\nnormalizing flows, we apply this method to the dequantization of smooth\r\nmanifold structures in order to model densities on the sphere, tori, and the\r\northogonal group.', 'We take the novel perspective to view data not as a probability distribution\r\nbut rather as a current. Primarily studied in the field of geometric measure\r\ntheory, $k$-currents are continuous linear functionals acting on compactly\r\nsupported smooth differential forms and can be understood as a generalized\r\nnotion of oriented $k$-dimensional manifold. By moving from distributions\r\n(which are $0$-currents) to $k$-currents, we can explicitly orient the data by\r\nattaching a $k$-dimensional tangent plane to each sample point. Based on the\r\nflat metric which is a fundamental distance between currents, we derive\r\nFlatGAN, a formulation in the spirit of generative adversarial networks but\r\ngeneralized to $k$-currents. In our theoretical contribution we prove that the\r\nflat metric between a parametrized current and a reference current is Lipschitz\r\ncontinuous in the parameters. In experiments, we show that the proposed shift\r\nto $k>0$ leads to interpretable and disentangled latent representations which\r\nbehave equivariantly to the specified oriented tangent planes.', 'We introduce an approach based on the Givens representation for posterior\r\ninference in statistical models with orthogonal matrix parameters, such as\r\nfactor models and probabilistic principal component analysis (PPCA). We show\r\nhow the Givens representation can be used to develop practical methods for\r\ntransforming densities over the Stiefel manifold into densities over subsets of\r\nEuclidean space. We show how to deal with issues arising from the topology of\r\nthe Stiefel manifold and how to inexpensively compute the change-of-measure\r\nterms. We introduce an auxiliary parameter approach that limits the impact of\r\ntopological issues. We provide both analysis of our methods and numerical\r\nexamples demonstrating the effectiveness of the approach. We also discuss how\r\nour Givens representation can be used to define general classes of\r\ndistributions over the space of orthogonal matrices. We then give\r\ndemonstrations on several examples showing how the Givens approach performs in\r\npractice in comparison with other methods.']","['Manifold Density Estimation via Generalized Dequantization', 'Flat Metric Minimization with Applications in Generative Modeling', 'Bayesian Inference over the Stiefel Manifold via the Givens Representation']","[['stat.ML', 'cs.LG'], ['cs.LG', 'cs.CV', 'stat.ML'], ['stat.ML']]","[0.8662109375, 0.8611139059066772, 0.8600804209709167]"
Where can the source code for STM be accessed?,a neural program synthesizer,"[""Program synthesis of general-purpose source code from natural language\r\nspecifications is challenging due to the need to reason about high-level\r\npatterns in the target program and low-level implementation details at the same\r\ntime. In this work, we present PATOIS, a system that allows a neural program\r\nsynthesizer to explicitly interleave high-level and low-level reasoning at\r\nevery generation step. It accomplishes this by automatically mining common code\r\nidioms from a given corpus, incorporating them into the underlying language for\r\nneural synthesis, and training a tree-based neural synthesizer to use these\r\nidioms during code generation. We evaluate PATOIS on two complex semantic\r\nparsing datasets and show that using learned code idioms improves the\r\nsynthesizer's accuracy."", 'We present basic notions of Gold\'s ""learnability in the limit"" paradigm,\r\nfirst presented in 1967, a formalization of the cognitive process by which a\r\nnative speaker gets to grasp the underlying grammar of his/her own native\r\nlanguage by being exposed to well formed sentences generated by that grammar.\r\nThen we present Lambek grammars, a formalism issued from categorial grammars\r\nwhich, although not as expressive as needed for a full formalization of natural\r\nlanguages, is particularly suited to easily implement a natural interface\r\nbetween syntax and semantics. In the last part of this work, we present a\r\nlearnability result for Rigid Lambek grammars from structured examples.', 'The success of machine learning algorithms often relies on a large amount of\r\nhigh-quality data to train well-performed models. However, data is a valuable\r\nresource and are always held by different parties in reality. An effective\r\nsolution to such a data isolation problem is to employ federated learning,\r\nwhich allows multiple parties to collaboratively train a model. In this paper,\r\nwe propose a Secure version of the widely used Maximum Mean Discrepancy (SMMD)\r\nbased on homomorphic encryption to enable effective knowledge transfer under\r\nthe data federation setting without compromising the data privacy. The proposed\r\nSMMD is able to avoid the potential information leakage in transfer learning\r\nwhen aligning the source and target data distribution. As a result, both the\r\nsource domain and target domain can fully utilize their data to build more\r\nscalable models. Experimental results demonstrate that our proposed SMMD is\r\nsecure and effective.']","['Program Synthesis and Semantic Parsing with Learned Code Idioms', 'A Study on Learnability for Rigid Lambek Grammars', 'Privacy-preserving Transfer Learning via Secure Maximum Mean Discrepancy']","[['cs.LG', 'cs.AI', 'cs.CL', 'cs.PL', 'stat.ML'], ['cs.LG'], ['cs.LG', 'stat.ML']]","[0.8277249336242676, 0.7881818413734436, 0.7863758206367493]"
What are the three main challenges in multi-task reinforcement learning?,data-inefficiency and limited generalization,"['Deep reinforcement learning enables algorithms to learn complex behavior,\r\ndeal with continuous action spaces and find good strategies in environments\r\nwith high dimensional state spaces. With deep reinforcement learning being an\r\nactive area of research and many concurrent inventions, we decided to focus on\r\na relatively simple robotic task to evaluate a set of ideas that might help to\r\nsolve recent reinforcement learning problems. We test a newly created\r\ncombination of two commonly used reinforcement learning methods, whether it is\r\nable to learn more effectively than a baseline. We also compare different ideas\r\nto preprocess information before it is fed to the reinforcement learning\r\nalgorithm. The goal of this strategy is to reduce training time and eventually\r\nhelp the algorithm to converge. The concluding evaluation proves the general\r\napplicability of the described concepts by testing them using a simulated\r\nenvironment. These concepts might be reused for future experiments.', 'Despite significant progress, deep reinforcement learning (RL) suffers from\r\ndata-inefficiency and limited generalization. Recent efforts apply\r\nmeta-learning to learn a meta-learner from a set of RL tasks such that a novel\r\nbut related task could be solved quickly. Though specific in some ways,\r\ndifferent tasks in meta-RL are generally similar at a high level. However, most\r\nmeta-RL methods do not explicitly and adequately model the specific and shared\r\ninformation among different tasks, which limits their ability to learn training\r\ntasks and to generalize to novel tasks. In this paper, we propose to capture\r\nthe shared information on the one hand and meta-learn how to quickly abstract\r\nthe specific information about a task on the other hand. Methodologically, we\r\ntrain an SGD meta-learner to quickly optimize a task encoder for each task,\r\nwhich generates a task embedding based on past experience. Meanwhile, we learn\r\na policy which is shared across all tasks and conditioned on task embeddings.\r\nEmpirical results on four simulated tasks demonstrate that our method has\r\nbetter learning capacity on both training and novel tasks and attains up to 3\r\nto 4 times higher returns compared to baselines.', 'In standard reinforcement learning (RL), a learning agent seeks to optimize\r\nthe overall reward. However, many key aspects of a desired behavior are more\r\nnaturally expressed as constraints. For instance, the designer may want to\r\nlimit the use of unsafe actions, increase the diversity of trajectories to\r\nenable exploration, or approximate expert trajectories when rewards are sparse.\r\nIn this paper, we propose an algorithmic scheme that can handle a wide class of\r\nconstraints in RL tasks: specifically, any constraints that require expected\r\nvalues of some vector measurements (such as the use of an action) to lie in a\r\nconvex set. This captures previously studied constraints (such as safety and\r\nproximity to an expert), but also enables new classes of constraints (such as\r\ndiversity). Our approach comes with rigorous theoretical guarantees and only\r\nrelies on the ability to approximately solve standard RL tasks. As a result, it\r\ncan be easily adapted to work with any model-free or model-based RL. In our\r\nexperiments, we show that it matches previous algorithms that enforce safety\r\nvia constraints, but can also enforce new properties that these algorithms do\r\nnot incorporate, such as diversity.']","['Using Deep Reinforcement Learning for the Continuous Control of Robotic Arms', 'Meta Reinforcement Learning with Task Embedding and Shared Policy', 'Reinforcement Learning with Convex Constraints']","[['cs.LG', 'cs.RO', 'stat.ML'], ['cs.LG', 'cs.AI', 'stat.ML'], ['cs.LG', 'cs.AI', 'cs.GT', 'stat.ML']]","[0.8801889419555664, 0.8771612644195557, 0.8758977651596069]"
What is the main goal of self-supervised methods in reinforcement learning?,contextual bandit learning,"[""Contextual bandits are a common problem faced by machine learning\r\npractitioners in domains as diverse as hypothesis testing to product\r\nrecommendations. There have been a lot of approaches in exploiting rich data\r\nrepresentations for contextual bandit problems with varying degree of success.\r\nSelf-supervised learning is a promising approach to find rich data\r\nrepresentations without explicit labels. In a typical self-supervised learning\r\nscheme, the primary task is defined by the problem objective (e.g. clustering,\r\nclassification, embedding generation etc.) and the secondary task is defined by\r\nthe self-supervision objective (e.g. rotation prediction, words in\r\nneighborhood, colorization, etc.). In the usual self-supervision, we learn\r\nimplicit labels from the training data for a secondary task. However, in the\r\ncontextual bandit setting, we don't have the advantage of getting implicit\r\nlabels due to lack of data in the initial phase of learning. We provide a novel\r\napproach to tackle this issue by combining a contextual bandit objective with a\r\nself supervision objective. By augmenting contextual bandit learning with\r\nself-supervision we get a better cumulative reward. Our results on eight\r\npopular computer vision datasets show substantial gains in cumulative reward.\r\nWe provide cases where the proposed scheme doesn't perform optimally and give\r\nalternative methods for better learning in these cases."", ""We propose a generic reward shaping approach for improving the rate of\r\nconvergence in reinforcement learning (RL), called Self Improvement Based\r\nREwards, or SIBRE. The approach is designed for use in conjunction with any\r\nexisting RL algorithm, and consists of rewarding improvement over the agent's\r\nown past performance. We prove that SIBRE converges in expectation under the\r\nsame conditions as the original RL algorithm. The reshaped rewards help\r\ndiscriminate between policies when the original rewards are weakly\r\ndiscriminated or sparse. Experiments on several well-known benchmark\r\nenvironments with different RL algorithms show that SIBRE converges to the\r\noptimal policy faster and more stably. We also perform sensitivity analysis\r\nwith respect to hyper-parameters, in comparison with baseline RL algorithms."", 'We present a modular neural network architecture Main that learns algorithms\r\ngiven a set of input-output examples. Main consists of a neural controller that\r\ninteracts with a variable-length input tape and learns to compose modules\r\ntogether with their corresponding argument choices. Unlike previous approaches,\r\nMain uses a general domain-agnostic mechanism for selection of modules and\r\ntheir arguments. It uses a general input tape layout together with a parallel\r\nhistory tape to indicate most recently used locations. Finally, it uses a\r\nmemoryless controller with a length-invariant self-attention based input tape\r\nencoding to allow for random access to tape locations. The Main architecture is\r\ntrained end-to-end using reinforcement learning from a set of input-output\r\nexamples. We evaluate Main on five algorithmic tasks and show that it can learn\r\npolicies that generalizes perfectly to inputs of much longer lengths than the\r\nones used for training.']","['Self-Supervised Contextual Bandits in Computer Vision', 'SIBRE: Self Improvement Based REwards for Adaptive Feedback in Reinforcement Learning', 'Towards Modular Algorithm Induction']","[['cs.CV', 'cs.LG', 'stat.ML'], ['cs.LG', 'cs.AI', 'stat.ML'], ['cs.LG', 'cs.AI']]","[0.887062668800354, 0.8858053088188171, 0.8824372291564941]"
How does the proposed Local and Global Diffusion (LGD) framework address this limitation?,We present a novel neural network architecture that learns the local and global representations in parallel.,"['Manifold learning techniques for dynamical systems and time series have shown\r\ntheir utility for a broad spectrum of applications in recent years. While these\r\nmethods are effective at learning a low-dimensional representation, they are\r\noften insufficient for visualizing the global and local structure of the data.\r\nIn this paper, we present DIG (Dynamical Information Geometry), a visualization\r\nmethod for multivariate time series data that extracts an information geometry\r\nfrom a diffusion framework. Specifically, we implement a novel group of\r\ndistances in the context of diffusion operators, which may be useful to reveal\r\nstructure in the data that may not be accessible by the commonly used diffusion\r\ndistances. Finally, we present a case study applying our visualization tool to\r\nEEG data to visualize sleep stages.', 'Convolutional Neural Networks (CNN) have been regarded as a powerful class of\r\nmodels for visual recognition problems. Nevertheless, the convolutional filters\r\nin these networks are local operations while ignoring the large-range\r\ndependency. Such drawback becomes even worse particularly for video\r\nrecognition, since video is an information-intensive media with complex\r\ntemporal variations. In this paper, we present a novel framework to boost the\r\nspatio-temporal representation learning by Local and Global Diffusion (LGD).\r\nSpecifically, we construct a novel neural network architecture that learns the\r\nlocal and global representations in parallel. The architecture is composed of\r\nLGD blocks, where each block updates local and global features by modeling the\r\ndiffusions between these two representations. Diffusions effectively interact\r\ntwo aspects of information, i.e., localized and holistic, for more powerful way\r\nof representation learning. Furthermore, a kernelized classifier is introduced\r\nto combine the representations from two aspects for video recognition. Our LGD\r\nnetworks achieve clear improvements on the large-scale Kinetics-400 and\r\nKinetics-600 video classification datasets against the best competitors by 3.5%\r\nand 0.7%. We further examine the generalization of both the global and local\r\nrepresentations produced by our pre-trained LGD networks on four different\r\nbenchmarks for video action recognition and spatio-temporal action detection\r\ntasks. Superior performances over several state-of-the-art techniques on these\r\nbenchmarks are reported. Code is available at:\r\nhttps://github.com/ZhaofanQiu/local-and-global-diffusion-networks.', 'We address the estimation of conditional average treatment effects (CATEs)\r\nwhen treatments are graph-structured (e.g., molecular graphs of drugs). Given a\r\nweak condition on the effect, we propose a plug-in estimator that decomposes\r\nCATE estimation into separate, simpler optimization problems. Our estimator (a)\r\nisolates the causal estimands (reducing regularization bias), and (b) allows\r\none to plug in arbitrary models for learning. In experiments with small-world\r\nand molecular graphs, we show that our approach outperforms prior approaches\r\nand is robust to varying selection biases. Our implementation is online.']","['Visualizing High Dimensional Dynamical Processes', 'Learning Spatio-Temporal Representation with Local and Global Diffusion', 'Graph Intervention Networks for Causal Effect Estimation']","[['stat.ML', 'cs.LG', 'eess.SP'], ['cs.CV'], ['cs.LG', 'stat.ML']]","[0.8832003474235535, 0.8781703114509583, 0.8705369234085083]"
What is the role of diffusions in the LGD network?,Local and Global Diffusion,"['Convolutional Neural Networks (CNN) have been regarded as a powerful class of\r\nmodels for visual recognition problems. Nevertheless, the convolutional filters\r\nin these networks are local operations while ignoring the large-range\r\ndependency. Such drawback becomes even worse particularly for video\r\nrecognition, since video is an information-intensive media with complex\r\ntemporal variations. In this paper, we present a novel framework to boost the\r\nspatio-temporal representation learning by Local and Global Diffusion (LGD).\r\nSpecifically, we construct a novel neural network architecture that learns the\r\nlocal and global representations in parallel. The architecture is composed of\r\nLGD blocks, where each block updates local and global features by modeling the\r\ndiffusions between these two representations. Diffusions effectively interact\r\ntwo aspects of information, i.e., localized and holistic, for more powerful way\r\nof representation learning. Furthermore, a kernelized classifier is introduced\r\nto combine the representations from two aspects for video recognition. Our LGD\r\nnetworks achieve clear improvements on the large-scale Kinetics-400 and\r\nKinetics-600 video classification datasets against the best competitors by 3.5%\r\nand 0.7%. We further examine the generalization of both the global and local\r\nrepresentations produced by our pre-trained LGD networks on four different\r\nbenchmarks for video action recognition and spatio-temporal action detection\r\ntasks. Superior performances over several state-of-the-art techniques on these\r\nbenchmarks are reported. Code is available at:\r\nhttps://github.com/ZhaofanQiu/local-and-global-diffusion-networks.', 'Manifold learning techniques for dynamical systems and time series have shown\r\ntheir utility for a broad spectrum of applications in recent years. While these\r\nmethods are effective at learning a low-dimensional representation, they are\r\noften insufficient for visualizing the global and local structure of the data.\r\nIn this paper, we present DIG (Dynamical Information Geometry), a visualization\r\nmethod for multivariate time series data that extracts an information geometry\r\nfrom a diffusion framework. Specifically, we implement a novel group of\r\ndistances in the context of diffusion operators, which may be useful to reveal\r\nstructure in the data that may not be accessible by the commonly used diffusion\r\ndistances. Finally, we present a case study applying our visualization tool to\r\nEEG data to visualize sleep stages.', 'We take the novel perspective to view data not as a probability distribution\r\nbut rather as a current. Primarily studied in the field of geometric measure\r\ntheory, $k$-currents are continuous linear functionals acting on compactly\r\nsupported smooth differential forms and can be understood as a generalized\r\nnotion of oriented $k$-dimensional manifold. By moving from distributions\r\n(which are $0$-currents) to $k$-currents, we can explicitly orient the data by\r\nattaching a $k$-dimensional tangent plane to each sample point. Based on the\r\nflat metric which is a fundamental distance between currents, we derive\r\nFlatGAN, a formulation in the spirit of generative adversarial networks but\r\ngeneralized to $k$-currents. In our theoretical contribution we prove that the\r\nflat metric between a parametrized current and a reference current is Lipschitz\r\ncontinuous in the parameters. In experiments, we show that the proposed shift\r\nto $k>0$ leads to interpretable and disentangled latent representations which\r\nbehave equivariantly to the specified oriented tangent planes.']","['Learning Spatio-Temporal Representation with Local and Global Diffusion', 'Visualizing High Dimensional Dynamical Processes', 'Flat Metric Minimization with Applications in Generative Modeling']","[['cs.CV'], ['stat.ML', 'cs.LG', 'eess.SP'], ['cs.LG', 'cs.CV', 'stat.ML']]","[0.8600986003875732, 0.8576536774635315, 0.8522981405258179]"
How many categories and images are included in the UDD dataset?,el,"['Learning to transfer visual attributes requires supervision dataset.\r\nCorresponding images with varying attribute values with the same identity are\r\nrequired for learning the transfer function. This largely limits their\r\napplications, because capturing them is often a difficult task. To address the\r\nissue, we propose an unsupervised method to learn to transfer visual attribute.\r\nThe proposed method can learn the transfer function without any corresponding\r\nimages. Inspecting visualization results from various unsupervised attribute\r\ntransfer tasks, we verify the effectiveness of the proposed method.', 'We consider the unsupervised learning problem of assigning labels to\r\nunlabeled data. A naive approach is to use clustering methods, but this works\r\nwell only when data is properly clustered and each cluster corresponds to an\r\nunderlying class. In this paper, we first show that this unsupervised labeling\r\nproblem in balanced binary cases can be solved if two unlabeled datasets having\r\ndifferent class balances are available. More specifically, estimation of the\r\nsign of the difference between probability densities of two unlabeled datasets\r\ngives the solution. We then introduce a new method to directly estimate the\r\nsign of the density difference without density estimation. Finally, we\r\ndemonstrate the usefulness of the proposed method against several clustering\r\nmethods on various toy problems and real-world datasets.', 'The majority of existing color naming methods focuses on the eleven basic\r\ncolor terms of the English language. However, in many applications, different\r\nsets of color names are used for the accurate description of objects. Labeling\r\ndata to learn these domain-specific color names is an expensive and laborious\r\ntask. Therefore, in this article we aim to learn color names from weakly\r\nlabeled data. For this purpose, we add an attention branch to the color naming\r\nnetwork. The attention branch is used to modulate the pixel-wise color naming\r\npredictions of the network. In experiments, we illustrate that the attention\r\nbranch correctly identifies the relevant regions. Furthermore, we show that our\r\nmethod obtains state-of-the-art results for pixel-wise and image-wise\r\nclassification on the EBAY dataset and is able to learn color names for various\r\ndomains.']","['Unsupervised Visual Attribute Transfer with Reconfigurable Generative Adversarial Networks', 'Clustering Unclustered Data: Unsupervised Binary Labeling of Two Datasets Having Different Class Balances', 'Weakly Supervised Domain-Specific Color Naming Based on Attention']","[['cs.CV'], ['cs.LG'], ['cs.CV']]","[0.8311767578125, 0.829493522644043, 0.8279050588607788]"
