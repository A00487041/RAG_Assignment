question,answer,Actual Answers,retrieved_docs,retrieved_titles,retrieved_terms,similarities,Manual Evaluation,Reason
What issue does consistency training face?,"a continual setup, data from different sources arrives sequentially and each batch is only available for a limited period",A: Models lose ability to exploit unlabeled data.,"['Continual learning protocols are attracting increasing attention from the\nmedical imaging community. In a continual setup, data from different sources\narrives sequentially and each batch is only available for a limited period.\nGiven the inherent privacy risks associated with medical data, this setup\nreflects the reality of deployment for deep learning diagnostic radiology\nsystems. Many techniques exist to learn continuously for classification tasks,\nand several have been adapted to semantic segmentation. Yet most have at least\none of the following flaws: a) they rely too heavily on domain identity\ninformation during inference, or b) data as seen in early training stages does\nnot profit from training with later data. In this work, we propose an\nevaluation framework that addresses both concerns, and introduce a fair\nmulti-model benchmark. We show that the benchmark outperforms two popular\ncontinual learning methods for the task of T2-weighted MR prostate\nsegmentation.', 'Modern deep neural networks struggle to transfer knowledge and generalize\nacross domains when deploying to real-world applications. Domain generalization\n(DG) aims to learn a universal representation from multiple source domains to\nimprove the network generalization ability on unseen target domains. Previous\nDG methods mostly focus on the data-level consistency scheme to advance the\ngeneralization capability of deep networks, without considering the synergistic\nregularization of different consistency schemes. In this paper, we present a\nnovel Hierarchical Consistency framework for Domain Generalization (HCDG) by\nensembling Extrinsic Consistency and Intrinsic Consistency. Particularly, for\nExtrinsic Consistency, we leverage the knowledge across multiple source domains\nto enforce data-level consistency. Also, we design a novel Amplitude\nGaussian-mixing strategy for Fourier-based data augmentation to enhance such\nconsistency. For Intrinsic Consistency, we perform task-level consistency for\nthe same instance under the dual-task form. We evaluate the proposed HCDG\nframework on two medical image segmentation tasks, i.e., optic cup/disc\nsegmentation on fundus images and prostate MRI segmentation. Extensive\nexperimental results manifest the effectiveness and versatility of our HCDG\nframework. Code will be available once accept.', ""While multiple studies have explored the relation between inter-rater\nvariability and deep learning model uncertainty in medical segmentation tasks,\nlittle is known about the impact of individual rater style. This study\nquantifies rater style in the form of bias and consistency and explores their\nimpacts when used to train deep learning models. Two multi-rater public\ndatasets were used, consisting of brain multiple sclerosis lesion and spinal\ncord grey matter segmentation. On both datasets, results show a correlation\n($R^2 = 0.60$ and $0.93$) between rater bias and deep learning uncertainty. The\nimpact of label fusion between raters' annotations on this relationship is also\nexplored, and we show that multi-center consensuses are more effective than\nsingle-center consensuses to reduce uncertainty, since rater style is mostly\ncenter-specific.""]","['What is Wrong with Continual Learning in Medical Image Segmentation?', 'HCDG: A Hierarchical Consistency Framework for Domain Generalization on Medical Image Segmentation', 'Impact of individual rater style on deep learning uncertainty in medical imaging segmentation']","[""['cs.CV', 'cs.LG']"", ""['cs.CV']"", ""['cs.CV', 'eess.IV']""]","[0.839682936668396, 0.8354004621505737, 0.8351045846939087]",Missing,Document retrieval fail
What is EHT used for?,medical image segmentation,A: Semantic segmentation of urban images.,"['The strict security requirements placed on medical records by various privacy\nregulations become major obstacles in the age of big data. To ensure efficient\nmachine learning as a service schemes while protecting data confidentiality, in\nthis work, we propose blind UNET (BUNET), a secure protocol that implements\nprivacy-preserving medical image segmentation based on the UNET architecture.\nIn BUNET, we efficiently utilize cryptographic primitives such as homomorphic\nencryption and garbled circuits (GC) to design a complete secure protocol for\nthe UNET neural architecture. In addition, we perform extensive architectural\nsearch in reducing the computational bottleneck of GC-based secure activation\nprotocols with high-dimensional input data. In the experiment, we thoroughly\nexamine the parameter space of our protocol, and show that we can achieve up to\n14x inference time reduction compared to the-state-of-the-art secure inference\ntechnique on a baseline architecture with negligible accuracy degradation.', 'Medical image segmentation plays an essential role in developing\ncomputer-assisted diagnosis and therapy systems, yet still faces many\nchallenges. In the past few years, the popular encoder-decoder architectures\nbased on CNNs (e.g., U-Net) have been successfully applied in the task of\nmedical image segmentation. However, due to the locality of convolution\noperations, they demonstrate limitations in learning global context and\nlong-range spatial relations. Recently, several researchers try to introduce\ntransformers to both the encoder and decoder components with promising results,\nbut the efficiency requires further improvement due to the high computational\ncomplexity of transformers. In this paper, we propose LeViT-UNet, which\nintegrates a LeViT Transformer module into the U-Net architecture, for fast and\naccurate medical image segmentation. Specifically, we use LeViT as the encoder\nof the LeViT-UNet, which better trades off the accuracy and efficiency of the\nTransformer block. Moreover, multi-scale feature maps from transformer blocks\nand convolutional blocks of LeViT are passed into the decoder via\nskip-connection, which can effectively reuse the spatial information of the\nfeature maps. Our experiments indicate that the proposed LeViT-UNet achieves\nbetter performance comparing to various competing methods on several\nchallenging medical image segmentation benchmarks including Synapse and ACDC.\nCode and models will be publicly available at\nhttps://github.com/apple1986/LeViT_UNet.', 'In this paper, we present UNet++, a new, more powerful architecture for\nmedical image segmentation. Our architecture is essentially a deeply-supervised\nencoder-decoder network where the encoder and decoder sub-networks are\nconnected through a series of nested, dense skip pathways. The re-designed skip\npathways aim at reducing the semantic gap between the feature maps of the\nencoder and decoder sub-networks. We argue that the optimizer would deal with\nan easier learning task when the feature maps from the decoder and encoder\nnetworks are semantically similar. We have evaluated UNet++ in comparison with\nU-Net and wide U-Net architectures across multiple medical image segmentation\ntasks: nodule segmentation in the low-dose CT scans of chest, nuclei\nsegmentation in the microscopy images, liver segmentation in abdominal CT\nscans, and polyp segmentation in colonoscopy videos. Our experiments\ndemonstrate that UNet++ with deep supervision achieves an average IoU gain of\n3.9 and 3.4 points over U-Net and wide U-Net, respectively.']","['BUNET: Blind Medical Image Segmentation Based on Secure UNET', 'LeViT-UNet: Make Faster Encoders with Transformer for Medical Image Segmentation', 'UNet++: A Nested U-Net Architecture for Medical Image Segmentation']","[""['cs.CV', 'cs.CR']"", ""['cs.CV']"", ""['cs.CV', 'cs.LG', 'eess.IV', 'stat.ML']""]","[0.8018316030502319, 0.7984381914138794, 0.7838506102561951]",Missing,Document retrieval fail
What challenge do deep models face?,Deep learning,A: Domain shifts between source and new data.,"['We present DLTK, a toolkit providing baseline implementations for efficient\nexperimentation with deep learning methods on biomedical images. It builds on\ntop of TensorFlow and its high modularity and easy-to-use examples allow for a\nlow-threshold access to state-of-the-art implementations for typical medical\nimaging problems. A comparison of DLTK\'s reference implementations of popular\nnetwork architectures for image segmentation demonstrates new top performance\non the publicly available challenge data ""Multi-Atlas Labeling Beyond the\nCranial Vault"". The average test Dice similarity coefficient of $81.5$ exceeds\nthe previously best performing CNN ($75.7$) and the accuracy of the challenge\nwinning method ($79.0$).', 'Deep Neural Networks (DNNs) are widely used for decision making in a myriad\nof critical applications, ranging from medical to societal and even judicial.\nGiven the importance of these decisions, it is crucial for us to be able to\ninterpret these models. We introduce a new method for interpreting image\nsegmentation models by learning regions of images in which noise can be applied\nwithout hindering downstream model performance. We apply this method to\nsegmentation of the pancreas in CT scans, and qualitatively compare the quality\nof the method to existing explainability techniques, such as Grad-CAM and\nocclusion sensitivity. Additionally we show that, unlike other methods, our\ninterpretability model can be quantitatively evaluated based on the downstream\nperformance over obscured images.', ""Deep Learning (DL) models are becoming larger, because the increase in model\nsize might offer significant accuracy gain. To enable the training of large\ndeep networks, data parallelism and model parallelism are two well-known\napproaches for parallel training. However, data parallelism does not help\nreduce memory footprint per device. In this work, we introduce Large deep 3D\nConvNets with Automated Model Parallelism (LAMP) and investigate the impact of\nboth input's and deep 3D ConvNets' size on segmentation accuracy. Through\nautomated model parallelism, it is feasible to train large deep 3D ConvNets\nwith a large input patch, even the whole image. Extensive experiments\ndemonstrate that, facilitated by the automated model parallelism, the\nsegmentation accuracy can be improved through increasing model size and input\ncontext size, and large input yields significant inference speedup compared\nwith sliding window of small patches in the inference. Code is\navailable\\footnote{https://monai.io/research/lamp-automated-model-parallelism}.""]","['DLTK: State of the Art Reference Implementations for Deep Learning on Medical Images', 'U-Noise: Learnable Noise Masks for Interpretable Image Segmentation', 'LAMP: Large Deep Nets with Automated Model Parallelism for Image Segmentation']","[""['cs.CV', 'cs.LG']"", ""['cs.CV']"", ""['cs.CV', 'cs.DC', 'cs.LG', 'cs.NE', 'eess.IV']""]","[0.8471152782440186, 0.8460106253623962, 0.8458845615386963]",Missing,Document retrieval fail
How does transfer learning reduce data labeling costs?,transfer learning,It uses knowledge from a related domain.,"['Machine learning has been utilized to perform tasks in many different domains\nsuch as classification, object detection, image segmentation and natural\nlanguage analysis. Data labeling has always been one of the most important\ntasks in machine learning. However, labeling large amounts of data increases\nthe monetary cost in machine learning. As a result, researchers started to\nfocus on reducing data annotation and labeling costs. Transfer learning was\ndesigned and widely used as an efficient approach that can reasonably reduce\nthe negative impact of limited data, which in turn, reduces the data\npreparation cost. Even transferring previous knowledge from a source domain\nreduces the amount of data needed in a target domain. However, large amounts of\nannotated data are still demanded to build robust models and improve the\nprediction accuracy of the model. Therefore, researchers started to pay more\nattention on auto annotation and labeling. In this survey paper, we provide a\nreview of previous techniques that focuses on optimized data annotation and\nlabeling for video, audio, and text data.', ""In this paper, we propose to tackle the problem of reducing discrepancies\nbetween multiple domains referred to as multi-source domain adaptation and\nconsider it under the target shift assumption: in all domains we aim to solve a\nclassification problem with the same output classes, but with labels'\nproportions differing across them. This problem, generally ignored in the vast\nmajority papers on domain adaptation papers, is nevertheless critical in\nreal-world applications, and we theoretically show its impact on the adaptation\nsuccess. To address this issue, we design a method based on optimal transport,\na theory that has been successfully used to tackle adaptation problems in\nmachine learning. Our method performs multi-source adaptation and target shift\ncorrection simultaneously by learning the class probabilities of the unlabeled\ntarget sample and the coupling allowing to align two (or more) probability\ndistributions. Experiments on both synthetic and real-world data related to\nsatellite image segmentation task show the superiority of the proposed method\nover the state-of-the-art."", 'Conventional transfer learning leverages weights of pre-trained networks, but\nmandates the need for similar neural architectures. Alternatively, knowledge\ndistillation can transfer knowledge between heterogeneous networks but often\nrequires access to the original training data or additional generative\nnetworks. Knowledge transfer between networks can be improved by being agnostic\nto the choice of network architecture and reducing the dependence on original\ntraining data. We propose a knowledge transfer approach from a teacher to a\nstudent network wherein we train the student on an independent transferal\ndataset, whose annotations are generated by the teacher. Experiments were\nconducted on five state-of-the-art networks for semantic segmentation and seven\ndatasets across three imaging modalities. We studied knowledge transfer from a\nsingle teacher, combination of knowledge transfer and fine-tuning, and\nknowledge transfer from multiple teachers. The student model with a single\nteacher achieved similar performance as the teacher; and the student model with\nmultiple teachers achieved better performance than the teachers. The salient\nfeatures of our algorithm include: 1)no need for original training data or\ngenerative networks, 2) knowledge transfer between different architectures, 3)\nease of implementation for downstream tasks by using the downstream task\ndataset as the transferal dataset, 4) knowledge transfer of an ensemble of\nmodels, trained independently, into one student model. Extensive experiments\ndemonstrate that the proposed algorithm is effective for knowledge transfer and\neasily tunable.']","['A Survey on Machine Learning Techniques for Auto Labeling of Video, Audio, and Text Data', 'Optimal Transport for Multi-source Domain Adaptation under Target Shift', 'Network-Agnostic Knowledge Transfer for Medical Image Segmentation']","[""['cs.LG']"", ""['stat.ML']"", ""['cs.CV']""]","[0.9167786240577698, 0.8745719194412231, 0.8726475238800049]",Correct, Document retrieval succes. Failed to answer
What is StructBoost in boosting algorithms?,a method for learning a single accurate predictor by linearly combining a set of weak structured learners,It combines weak structured learners for prediction.,"['Boosting is a method for learning a single accurate predictor by linearly\ncombining a set of less accurate weak learners. Recently, structured learning\nhas found many applications in computer vision. Inspired by structured support\nvector machines (SSVM), here we propose a new boosting algorithm for structured\noutput prediction, which we refer to as StructBoost. StructBoost supports\nnonlinear structured learning by combining a set of weak structured learners.\nAs SSVM generalizes SVM, our StructBoost generalizes standard boosting\napproaches such as AdaBoost, or LPBoost to structured learning. The resulting\noptimization problem of StructBoost is more challenging than SSVM in the sense\nthat it may involve exponentially many variables and constraints. In contrast,\nfor SSVM one usually has an exponential number of constraints and a\ncutting-plane method is used. In order to efficiently solve StructBoost, we\nformulate an equivalent $ 1 $-slack formulation and solve it using a\ncombination of cutting planes and column generation. We show the versatility\nand usefulness of StructBoost on a range of problems such as optimizing the\ntree loss for hierarchical multi-class classification, optimizing the Pascal\noverlap criterion for robust visual tracking and learning conditional random\nfield parameters for image segmentation.', 'Complex classification performance metrics such as the F${}_\\beta$-measure\nand Jaccard index are often used, in order to handle class-imbalanced cases\nsuch as information retrieval and image segmentation. These performance metrics\nare not decomposable, that is, they cannot be expressed in a per-example\nmanner, which hinders a straightforward application of M-estimation widely used\nin supervised learning. In this paper, we consider linear-fractional metrics,\nwhich are a family of classification performance metrics that encompasses many\nstandard ones such as the F${}_\\beta$-measure and Jaccard index, and propose\nmethods to directly maximize performances under those metrics. A clue to tackle\ntheir direct optimization is a calibrated surrogate utility, which is a\ntractable lower bound of the true utility function representing a given metric.\nWe characterize sufficient conditions which make the surrogate maximization\ncoincide with the maximization of the true utility. Simulation results on\nbenchmark datasets validate the effectiveness of our calibrated surrogate\nmaximization especially if the sample sizes are extremely small.', 'We consider the structured-output prediction problem through probabilistic\napproaches and generalize the ""perturb-and-MAP"" framework to more challenging\nweighted Hamming losses, which are crucial in applications. While in principle\nour approach is a straightforward marginalization, it requires solving many\nrelated MAP inference problems. We show that for log-supermodular pairwise\nmodels these operations can be performed efficiently using the machinery of\ndynamic graph cuts. We also propose to use double stochastic gradient descent,\nboth on the data and on the perturbations, for efficient learning. Our\nframework can naturally take weak supervision (e.g., partial labels) into\naccount. We conduct a set of experiments on medium-scale character recognition\nand image segmentation, showing the benefits of our algorithms.']","['StructBoost: Boosting Methods for Predicting Structured Output Variables', 'Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification', 'Marginal Weighted Maximum Log-likelihood for Efficient Learning of Perturb-and-Map models']","[""['cs.LG']"", ""['cs.LG', 'stat.ML']"", ""['stat.ML', 'cs.LG']""]","[0.9142849445343018, 0.8487935066223145, 0.8477636575698853]",Correct,Document retrieval success. Right answer
What problem does Augmented CycleGAN address?,Learning inter-domain mappings from unpaired data,It learns many-to-many domain mappings.,"['Learning inter-domain mappings from unpaired data can improve performance in\nstructured prediction tasks, such as image segmentation, by reducing the need\nfor paired data. CycleGAN was recently proposed for this problem, but\ncritically assumes the underlying inter-domain mapping is approximately\ndeterministic and one-to-one. This assumption renders the model ineffective for\ntasks requiring flexible, many-to-many mappings. We propose a new model, called\nAugmented CycleGAN, which learns many-to-many mappings between domains. We\nexamine Augmented CycleGAN qualitatively and quantitatively on several image\ndatasets.', 'Generative adversarial networks (GANs) have shown great success in\napplications such as image generation and inpainting. However, they typically\nrequire large datasets, which are often not available, especially in the\ncontext of prediction tasks such as image segmentation that require labels.\nTherefore, methods such as the CycleGAN use more easily available unlabelled\ndata, but do not offer a way to leverage additional labelled data for improved\nperformance. To address this shortcoming, we show how to factorise the joint\ndata distribution into a set of lower-dimensional distributions along with\ntheir dependencies. This allows splitting the discriminator in a GAN into\nmultiple ""sub-discriminators"" that can be independently trained from incomplete\nobservations. Their outputs can be combined to estimate the density ratio\nbetween the joint real and the generator distribution, which enables training\ngenerators as in the original GAN framework. We apply our method to image\ngeneration, image segmentation and audio source separation, and obtain improved\nperformance over a standard GAN when additional incomplete training examples\nare available. For the Cityscapes segmentation task in particular, our method\nalso improves accuracy by an absolute 14.9% over CycleGAN while using only 25\nadditional paired examples.', ""We tackle the problem of graph partitioning for image segmentation using\ncorrelation clustering (CC), which we treat as an integer linear program (ILP).\nWe reformulate optimization in the ILP so as to admit efficient optimization\nvia Benders decomposition, a classic technique from operations research. Our\nBenders decomposition formulation has many subproblems, each associated with a\nnode in the CC instance's graph, which are solved in parallel. Each Benders\nsubproblem enforces the cycle inequalities corresponding to the negative weight\nedges attached to its corresponding node in the CC instance. We generate\nMagnanti-Wong Benders rows in addition to standard Benders rows, to accelerate\noptimization. Our Benders decomposition approach provides a promising new\navenue to accelerate optimization for CC, and allows for massive\nparallelization.""]","['Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data', 'Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators', 'Massively Parallel Benders Decomposition for Correlation Clustering']","[""['cs.LG']"", ""['cs.LG', 'stat.ML']"", ""['cs.CV', 'cs.DS']""]","[0.8618714809417725, 0.8375003337860107, 0.8293293118476868]",Correct,Document retrieval success. Right answer
What does the new algorithm for transductive inference optimize?,Lazy Modular Bayesian Optimization,It optimizes classifier parameters and label variables.,"['This paper introduces a novel algorithm for transductive inference in\nhigher-order MRFs, where the unary energies are parameterized by a variable\nclassifier. The considered task is posed as a joint optimization problem in the\ncontinuous classifier parameters and the discrete label variables. In contrast\nto prior approaches such as convex relaxations, we propose an advantageous\ndecoupling of the objective function into discrete and continuous subproblems\nand a novel, efficient optimization method related to ADMM. This approach\npreserves integrality of the discrete label variables and guarantees global\nconvergence to a critical point. We demonstrate the advantages of our approach\nin several experiments including video object segmentation on the DAVIS data\nset and interactive image segmentation.', 'Most existing black-box optimization methods assume that all variables in the\nsystem being optimized have equal cost and can change freely at each iteration.\nHowever, in many real world systems, inputs are passed through a sequence of\ndifferent operations or modules, making variables in earlier stages of\nprocessing more costly to update. Such structure imposes a cost on switching\nvariables in early parts of a data processing pipeline. In this work, we\npropose a new algorithm for switch cost-aware optimization called Lazy Modular\nBayesian Optimization (LaMBO). This method efficiently identifies the global\noptimum while minimizing cost through a passive change of variables in early\nmodules. The method is theoretical grounded and achieves vanishing regret when\naugmented with switching cost. We apply LaMBO to multiple synthetic functions\nand a three-stage image segmentation pipeline used in a neuroscience\napplication, where we obtain promising improvements over prevailing cost-aware\nBayesian optimization algorithms. Our results demonstrate that LaMBO is an\neffective strategy for black-box optimization that is capable of minimizing\nswitching costs in modular systems.', 'Performing inference in graphs is a common task within several machine\nlearning problems, e.g., image segmentation, community detection, among others.\nFor a given undirected connected graph, we tackle the statistical problem of\nexactly recovering an unknown ground-truth binary labeling of the nodes from a\nsingle corrupted observation of each edge. Such problem can be formulated as a\nquadratic combinatorial optimization problem over the boolean hypercube, where\nit has been shown before that one can (with high probability and in polynomial\ntime) exactly recover the ground-truth labeling of graphs that have an\nisoperimetric number that grows with respect to the number of nodes (e.g.,\ncomplete graphs, regular expanders). In this work, we apply a powerful\nhierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the\ncombinatorial problem. Motivated by empirical evidence on the improvement in\nexact recoverability, we center our attention on the degree-4 SoS relaxation\nand set out to understand the origin of such improvement from a graph\ntheoretical perspective. We show that the solution of the dual of the relaxed\nproblem is related to finding edge weights of the Johnson and Kneser graphs,\nwhere the weights fulfill the SoS constraints and intuitively allow the input\ngraph to increase its algebraic connectivity. Finally, as byproduct of our\nanalysis, we derive a novel Cheeger-type lower bound for the algebraic\nconnectivity of graphs with signed edge weights.']","['Discrete-Continuous ADMM for Transductive Inference in Higher-Order MRFs', 'Bayesian optimization for modular black-box systems with switching costs', 'A Thorough View of Exact Inference in Graphs from the Degree-4 Sum-of-Squares Hierarchy']","[""['cs.LG']"", ""['cs.LG', 'stat.ML']"", ""['cs.LG', 'cs.AI', 'stat.ML']""]","[0.9107867479324341, 0.8744175434112549, 0.8731463551521301]",Correct,Document retrieval success. But the answer was generated from the 2nd document as we collected total 3 documents
What does DSAL combine for image segmentation?,Chan-Vese model,Active learning and semi-supervised learning.,"['In order to completely separate objects with large sections of occluded\nboundaries in an image, we devise a new variational level set model for image\nsegmentation combining the Chan-Vese model with elastica and landmark\nconstraints. For computational efficiency, we design its Augmented Lagrangian\nMethod (ALM) or Alternating Direction Method of Multiplier (ADMM) method by\nintroducing some auxiliary variables, Lagrange multipliers, and penalty\nparameters. In each loop of alternating iterative optimization, the\nsub-problems of minimization can be easily solved via the Gauss-Seidel\niterative method and generalized soft thresholding formulas with projection,\nrespectively. Numerical experiments show that the proposed model can not only\nrecover larger broken boundaries but can also improve segmentation efficiency,\nas well as decrease the dependence of segmentation on parameter tuning and\ninitialization.', 'In a class of piecewise-constant image segmentation models, we propose to\nincorporate a weighted difference of anisotropic and isotropic total variation\n(AITV) to regularize the partition boundaries in an image. In particular, we\nreplace the total variation regularization in the Chan-Vese segmentation model\nand a fuzzy region competition model by the proposed AITV. To deal with the\nnonconvex nature of AITV, we apply the difference-of-convex algorithm (DCA), in\nwhich the subproblems can be minimized by the primal-dual hybrid gradient\nmethod with linesearch. The convergence of the DCA scheme is analyzed. In\naddition, a generalization to color image segmentation is discussed. In the\nnumerical experiments, we compare the proposed models with the classic convex\napproaches and the two-stage segmentation methods (smoothing and then\nthresholding) on various images, showing that our models are effective in image\nsegmentation and robust with respect to impulsive noises.', 'Superpixel algorithms, which group pixels similar in color and other\nlow-level properties, are increasingly used for pre-processing in image\nsegmentation. Commonly important criteria for the computation of superpixels\nare boundary adherence, speed, and regularity.\n  Boundary adherence and regularity are typically contradictory goals. Most\nrecent algorithms have focused on improving boundary adherence. Motivated by\nimproving superpixel regularity, we propose a diagram-based superpixel\ngeneration method called Power-SLIC.\n  On the BSDS500 data set, Power-SLIC outperforms other state-of-the-art\nalgorithms in terms of compactness and boundary precision, and its boundary\nadherence is the most robust against varying levels of Gaussian noise. In terms\nof speed, Power-SLIC is competitive with SLIC.']","['The Chan-Vese Model with Elastica and Landmark Constraints for Image Segmentation', 'A Weighted Difference of Anisotropic and Isotropic Total Variation for Relaxed Mumford-Shah Color and Multiphase Image Segmentation', 'Power-SLIC: Diagram-based superpixel generation']","[""['cs.CV']"", ""['cs.CV']"", ""['cs.CV', 'cs.CG', 'cs.LG']""]","[0.8865311145782471, 0.8848080039024353, 0.8827061653137207]",Missing,Document retrieval fail
What problem does StructBoost address in multi-source domain adaptation?,reducing discrepancies between multiple domains referred to as multi-source domain adaptation,"""It addresses discrepancies due to target shift across multiple domains.""","[""In this paper, we propose to tackle the problem of reducing discrepancies\nbetween multiple domains referred to as multi-source domain adaptation and\nconsider it under the target shift assumption: in all domains we aim to solve a\nclassification problem with the same output classes, but with labels'\nproportions differing across them. This problem, generally ignored in the vast\nmajority papers on domain adaptation papers, is nevertheless critical in\nreal-world applications, and we theoretically show its impact on the adaptation\nsuccess. To address this issue, we design a method based on optimal transport,\na theory that has been successfully used to tackle adaptation problems in\nmachine learning. Our method performs multi-source adaptation and target shift\ncorrection simultaneously by learning the class probabilities of the unlabeled\ntarget sample and the coupling allowing to align two (or more) probability\ndistributions. Experiments on both synthetic and real-world data related to\nsatellite image segmentation task show the superiority of the proposed method\nover the state-of-the-art."", 'Boosting is a method for learning a single accurate predictor by linearly\ncombining a set of less accurate weak learners. Recently, structured learning\nhas found many applications in computer vision. Inspired by structured support\nvector machines (SSVM), here we propose a new boosting algorithm for structured\noutput prediction, which we refer to as StructBoost. StructBoost supports\nnonlinear structured learning by combining a set of weak structured learners.\nAs SSVM generalizes SVM, our StructBoost generalizes standard boosting\napproaches such as AdaBoost, or LPBoost to structured learning. The resulting\noptimization problem of StructBoost is more challenging than SSVM in the sense\nthat it may involve exponentially many variables and constraints. In contrast,\nfor SSVM one usually has an exponential number of constraints and a\ncutting-plane method is used. In order to efficiently solve StructBoost, we\nformulate an equivalent $ 1 $-slack formulation and solve it using a\ncombination of cutting planes and column generation. We show the versatility\nand usefulness of StructBoost on a range of problems such as optimizing the\ntree loss for hierarchical multi-class classification, optimizing the Pascal\noverlap criterion for robust visual tracking and learning conditional random\nfield parameters for image segmentation.', 'We present the 2017 Visual Domain Adaptation (VisDA) dataset and challenge, a\nlarge-scale testbed for unsupervised domain adaptation across visual domains.\nUnsupervised domain adaptation aims to solve the real-world problem of domain\nshift, where machine learning models trained on one domain must be transferred\nand adapted to a novel visual domain without additional supervision. The\nVisDA2017 challenge is focused on the simulation-to-reality shift and has two\nassociated tasks: image classification and image segmentation. The goal in both\ntracks is to first train a model on simulated, synthetic data in the source\ndomain and then adapt it to perform well on real image data in the unlabeled\ntest domain. Our dataset is the largest one to date for cross-domain object\nclassification, with over 280K images across 12 categories in the combined\ntraining, validation and testing domains. The image segmentation dataset is\nalso large-scale with over 30K images across 18 categories in the three\ndomains. We compare VisDA to existing cross-domain adaptation datasets and\nprovide a baseline performance analysis using various domain adaptation models\nthat are currently popular in the field.']","['Optimal Transport for Multi-source Domain Adaptation under Target Shift', 'StructBoost: Boosting Methods for Predicting Structured Output Variables', 'VisDA: The Visual Domain Adaptation Challenge']","[""['stat.ML']"", ""['cs.LG']"", ""['cs.CV']""]","[0.8869342803955078, 0.8852487206459045, 0.8783530592918396]",Correct,Document retrieval success. Right answer
What is the benefit of using surrogate maximization for performance metrics?,We characterize sufficient conditions which make the surrogate maximization coincide with the maximization of the true utility,"""It allows direct maximization of complex classification metrics.""","['Complex classification performance metrics such as the F${}_\\beta$-measure\nand Jaccard index are often used, in order to handle class-imbalanced cases\nsuch as information retrieval and image segmentation. These performance metrics\nare not decomposable, that is, they cannot be expressed in a per-example\nmanner, which hinders a straightforward application of M-estimation widely used\nin supervised learning. In this paper, we consider linear-fractional metrics,\nwhich are a family of classification performance metrics that encompasses many\nstandard ones such as the F${}_\\beta$-measure and Jaccard index, and propose\nmethods to directly maximize performances under those metrics. A clue to tackle\ntheir direct optimization is a calibrated surrogate utility, which is a\ntractable lower bound of the true utility function representing a given metric.\nWe characterize sufficient conditions which make the surrogate maximization\ncoincide with the maximization of the true utility. Simulation results on\nbenchmark datasets validate the effectiveness of our calibrated surrogate\nmaximization especially if the sample sizes are extremely small.', ""The Dice score and Jaccard index are commonly used metrics for the evaluation\nof segmentation tasks in medical imaging. Convolutional neural networks trained\nfor image segmentation tasks are usually optimized for (weighted)\ncross-entropy. This introduces an adverse discrepancy between the learning\noptimization objective (the loss) and the end target metric. Recent works in\ncomputer vision have proposed soft surrogates to alleviate this discrepancy and\ndirectly optimize the desired metric, either through relaxations (soft-Dice,\nsoft-Jaccard) or submodular optimization (Lov\\'asz-softmax). The aim of this\nstudy is two-fold. First, we investigate the theoretical differences in a risk\nminimization framework and question the existence of a weighted cross-entropy\nloss with weights theoretically optimized to surrogate Dice or Jaccard. Second,\nwe empirically investigate the behavior of the aforementioned loss functions\nw.r.t. evaluation with Dice score and Jaccard index on five medical\nsegmentation tasks. Through the application of relative approximation bounds,\nwe show that all surrogates are equivalent up to a multiplicative factor, and\nthat no optimal weighting of cross-entropy exists to approximate Dice or\nJaccard measures. We validate these findings empirically and show that, while\nit is important to opt for one of the target metric surrogates rather than a\ncross-entropy-based loss, the choice of the surrogate does not make a\nstatistical difference on a wide range of medical segmentation tasks."", 'Most existing black-box optimization methods assume that all variables in the\nsystem being optimized have equal cost and can change freely at each iteration.\nHowever, in many real world systems, inputs are passed through a sequence of\ndifferent operations or modules, making variables in earlier stages of\nprocessing more costly to update. Such structure imposes a cost on switching\nvariables in early parts of a data processing pipeline. In this work, we\npropose a new algorithm for switch cost-aware optimization called Lazy Modular\nBayesian Optimization (LaMBO). This method efficiently identifies the global\noptimum while minimizing cost through a passive change of variables in early\nmodules. The method is theoretical grounded and achieves vanishing regret when\naugmented with switching cost. We apply LaMBO to multiple synthetic functions\nand a three-stage image segmentation pipeline used in a neuroscience\napplication, where we obtain promising improvements over prevailing cost-aware\nBayesian optimization algorithms. Our results demonstrate that LaMBO is an\neffective strategy for black-box optimization that is capable of minimizing\nswitching costs in modular systems.']","['Calibrated Surrogate Maximization of Linear-fractional Utility in Binary Classification', 'Optimizing the Dice Score and Jaccard Index for Medical Image Segmentation: Theory & Practice', 'Bayesian optimization for modular black-box systems with switching costs']","[""['cs.LG', 'stat.ML']"", ""['cs.CV', 'cs.LG', 'eess.IV']"", ""['cs.LG', 'stat.ML']""]","[0.8967105746269226, 0.8617841005325317, 0.8603100180625916]",Correct,Document retrieval success. Right answer
How does the point-set kernel measure compute similarity between objects?,k-means clustering,"""It computes similarity between an object and a sample from an unknown distribution.""","['Measuring similarity between two objects is the core operation in existing\ncluster analyses in grouping similar objects into clusters. Cluster analyses\nhave been applied to a number of applications, including image segmentation,\nsocial network analysis, and computational biology. This paper introduces a new\nsimilarity measure called point-set kernel which computes the similarity\nbetween an object and a sample of objects generated from an unknown\ndistribution. The proposed clustering procedure utilizes this new measure to\ncharacterize both the typical point of every cluster and the cluster grown from\nthe typical point. We show that the new clustering procedure is both effective\nand efficient such that it can deal with large scale datasets. In contrast,\nexisting clustering algorithms are either efficient or effective; and even\nefficient ones have difficulty dealing with large scale datasets without\nspecial hardware. We show that the proposed algorithm is more effective and\nruns orders of magnitude faster than the state-of-the-art density-peak\nclustering and scalable kernel k-means clustering when applying to datasets of\nmillions of data points, on commonly used computing machines.', 'We provide initial seedings to the Quick Shift clustering algorithm, which\napproximate the locally high-density regions of the data. Such seedings act as\nmore stable and expressive cluster-cores than the singleton modes found by\nQuick Shift. We establish statistical consistency guarantees for this\nmodification. We then show strong clustering performance on real datasets as\nwell as promising applications to image segmentation.', 'Motivated by a $2$-dimensional (unsupervised) image segmentation task whereby\nlocal regions of pixels are clustered via edge detection methods, a more\ngeneral probabilistic mathematical framework is devised. Critical thresholds\nare calculated that indicate strong correlation between randomly-generated,\nhigh dimensional data points that have been projected into structures in a\npartition of a bounded, $2$-dimensional area, of which, an image is a special\ncase. A neighbor concept for structures in the partition is defined and a\ncritical radius is uncovered. Measured from a central structure in localized\nregions of the partition, the radius indicates strong, long and short range\ncorrelation in the count of occupied structures. The size of a short interval\nof radii is estimated upon which the transition from short-to-long range\ncorrelation is virtually assured, which defines a demarcation of when an image\nceases to be ""interesting"".']","['Clustering based on Point-Set Kernel', 'Quickshift++: Provably Good Initializations for Sample-Based Mean Shift', 'A Critical Connectivity Radius for Segmenting Randomly-Generated, High Dimensional Data Points']","[""['cs.LG', 'stat.ML']"", ""['cs.LG', 'stat.ML']"", ""['cs.LG', '60D05, 62C99']""]","[0.9056169390678406, 0.8723191022872925, 0.8708831071853638]",Correct,Document retrieval success. Almost Right answer
How does the 'Adversarial Payload Loss' evade malware detection while preserving functionality?,by injecting a small sequence of bytes,It injects payloads maintaining benign file characteristics.,"['In recent years, deep learning has shown performance breakthroughs in many\napplications, such as image detection, image segmentation, pose estimation, and\nspeech recognition. However, this comes with a major concern: deep networks\nhave been found to be vulnerable to adversarial examples. Adversarial examples\nare slightly modified inputs that are intentionally designed to cause a\nmisclassification by the model. In the domains of images and speech, the\nmodifications are so small that they are not seen or heard by humans, but\nnevertheless greatly affect the classification of the model.\n  Deep learning models have been successfully applied to malware detection. In\nthis domain, generating adversarial examples is not straightforward, as small\nmodifications to the bytes of the file could lead to significant changes in its\nfunctionality and validity. We introduce a novel loss function for generating\nadversarial examples specifically tailored for discrete input sets, such as\nexecutable bytes. We modify malicious binaries so that they would be detected\nas benign, while preserving their original functionality, by injecting a small\nsequence of bytes (payload) in the binary file. We applied this approach to an\nend-to-end convolutional deep learning malware detection model and show a high\nrate of detection evasion. Moreover, we show that our generated payload is\nrobust enough to be transferable within different locations of the same file\nand across different files, and that its entropy is low and similar to that of\nbenign data sections.', 'At present, adversarial attacks are designed in a task-specific fashion.\nHowever, for downstream computer vision tasks such as image captioning, image\nsegmentation etc., the current deep learning systems use an image classifier\nlike VGG16, ResNet50, Inception-v3 etc. as a feature extractor. Keeping this in\nmind, we propose Mimic and Fool, a task agnostic adversarial attack. Given a\nfeature extractor, the proposed attack finds an adversarial image which can\nmimic the image feature of the original image. This ensures that the two images\ngive the same (or similar) output regardless of the task. We randomly select\n1000 MSCOCO validation images for experimentation. We perform experiments on\ntwo image captioning models, Show and Tell, Show Attend and Tell and one VQA\nmodel, namely, end-to-end neural module network (N2NMN). The proposed attack\nachieves success rate of 74.0%, 81.0% and 87.1% for Show and Tell, Show Attend\nand Tell and N2NMN respectively. We also propose a slight modification to our\nattack to generate natural-looking adversarial images. In addition, we also\nshow the applicability of the proposed attack for invertible architecture.\nSince Mimic and Fool only requires information about the feature extractor of\nthe model, it can be considered as a gray-box attack.', ""Applications such as autonomous vehicles and medical screening use deep\nlearning models to localize and identify hundreds of objects in a single frame.\nIn the past, it has been shown how an attacker can fool these models by placing\nan adversarial patch within a scene. However, these patches must be placed in\nthe target location and do not explicitly alter the semantics elsewhere in the\nimage.\n  In this paper, we introduce a new type of adversarial patch which alters a\nmodel's perception of an image's semantics. These patches can be placed\nanywhere within an image to change the classification or semantics of locations\nfar from the patch. We call this new class of adversarial examples `remote\nadversarial patches' (RAP).\n  We implement our own RAP called IPatch and perform an in-depth analysis on\nimage segmentation RAP attacks using five state-of-the-art architectures with\neight different encoders on the CamVid street view dataset. Moreover, we\ndemonstrate that the attack can be extended to object recognition models with\npreliminary results on the popular YOLOv3 model. We found that the patch can\nchange the classification of a remote target region with a success rate of up\nto 93% on average.""]","['Deceiving End-to-End Deep Learning Malware Detectors using Adversarial Examples', 'Mimic and Fool: A Task Agnostic Adversarial Attack', 'IPatch: A Remote Adversarial Patch']","[""['cs.LG', 'cs.CR']"", ""['cs.CV']"", ""['cs.CV', 'cs.AI', 'cs.CR', 'cs.LG']""]","[0.8960573673248291, 0.8749409914016724, 0.8604234457015991]",Correct,Document retrieval success. Right answer
How does AI-powered 3D image segmentation enable personalized treatment planning in oncology?,Using AI-powered 3D image segmentation,"It provides accurate, automated tissue measurements for treatment.","['The semantic image segmentation task consists of classifying each pixel of an\nimage into an instance, where each instance corresponds to a class. This task\nis a part of the concept of scene understanding or better explaining the global\ncontext of an image. In the medical image analysis domain, image segmentation\ncan be used for image-guided interventions, radiotherapy, or improved\nradiological diagnostics. In this review, we categorize the leading deep\nlearning-based medical and non-medical image segmentation solutions into six\nmain groups of deep architectural, data synthesis-based, loss function-based,\nsequenced models, weakly supervised, and multi-task methods and provide a\ncomprehensive review of the contributions in each of these groups. Further, for\neach group, we analyze each variant of these groups and discuss the limitations\nof the current approaches and present potential future research directions for\nsemantic image segmentation.', 'The latest advances in computer-assisted precision medicine are making it\nfeasible to move from population-wide models that are useful to discover\naggregate patterns that hold for group-based analysis to patient-specific\nmodels that can drive patient-specific decisions with regard to treatment\nchoices, and predictions of outcomes of treatment. Body Composition is\nrecognized as an important driver and risk factor for a wide variety of\ndiseases, as well as a predictor of individual patient-specific clinical\noutcomes to treatment choices or surgical interventions. 3D CT images are\nroutinely acquired in the oncological worklows and deliver accurate rendering\nof internal anatomy and therefore can be used opportunistically to assess the\namount of skeletal muscle and adipose tissue compartments. Powerful tools of\nartificial intelligence such as deep learning are making it feasible now to\nsegment the entire 3D image and generate accurate measurements of all internal\nanatomy. These will enable the overcoming of the severe bottleneck that existed\npreviously, namely, the need for manual segmentation, which was prohibitive to\nscale to the hundreds of 2D axial slices that made up a 3D volumetric image.\nAutomated tools such as presented here will now enable harvesting whole-body\nmeasurements from 3D CT or MRI images, leading to a new era of discovery of the\ndrivers of various diseases based on individual tissue, organ volume, shape,\nand functional status. These measurements were hitherto unavailable thereby\nlimiting the field to a very small and limited subset. These discoveries and\nthe potential to perform individual image segmentation with high speed and\naccuracy are likely to lead to the incorporation of these 3D measures into\nindividual specific treatment planning models related to nutrition, aging,\nchemotoxicity, surgery and survival after the onset of a major disease such as\ncancer.', 'In interactive medical image segmentation, anatomical structures are\nextracted from reconstructed volumetric images. The first iterations of user\ninteraction traditionally consist of drawing pictorial hints as an initial\nestimate of the object to extract. Only after this time consuming first phase,\nthe efficient selective refinement of current segmentation results begins.\nErroneously labeled seeds, especially near the border of the object, are\nchallenging to detect and replace for a human and may substantially impact the\noverall segmentation quality. We propose an automatic seeding pipeline as well\nas a configuration based on saliency recognition, in order to skip the\ntime-consuming initial interaction phase during segmentation. A median Dice\nscore of 68.22% is reached before the first user interaction on the test data\nset with an error rate in seeding of only 0.088%.']","['Deep Semantic Segmentation of Natural and Medical Images: A Review', 'Comprehensive Validation of Automated Whole Body Skeletal Muscle, Adipose Tissue, and Bone Segmentation from 3D CT images for Body Composition Analysis: Towards Extended Body Composition', 'Robust Seed Mask Generation for Interactive Image Segmentation']","[""['cs.CV', 'cs.LG', 'eess.IV']"", ""['cs.CV', 'q-bio.TO']"", ""['cs.CV']""]","[0.9105475544929504, 0.9061556458473206, 0.90566086769104]",Correct,Document retrieval success. Almost Right answer
What strategies can be used to enhance teamwork and communication in Agile environments?,Reinforcement learning,"Frequent stand-ups, clear roles, and collaborative tools.","['Interactive image segmentation algorithms rely on the user to provide\nannotations as the guidance. When the task of interactive segmentation is\nperformed on a small touchscreen device, the requirement of providing precise\nannotations could be cumbersome to the user. We design an efficient seed\nproposal method that actively proposes annotation seeds for the user to label.\nThe user only needs to check which ones of the query seeds are inside the\nregion of interest (ROI). We enforce the sparsity and diversity criteria on the\nselection of the query seeds. At each round of interaction the user is only\npresented with a small number of informative query seeds that are far apart\nfrom each other. As a result, we are able to derive a user friendly interaction\nmechanism for annotation on small touchscreen devices. The user merely has to\nswipe through on the ROI-relevant query seeds, which should be easy since those\ngestures are commonly used on a touchscreen. The performance of our algorithm\nis evaluated on six publicly available datasets. The evaluation results show\nthat our algorithm achieves high segmentation accuracy, with short response\ntime and less user feedback.', 'Optimal decision making with limited or no information in stochastic\nenvironments where multiple agents interact is a challenging topic in the realm\nof artificial intelligence. Reinforcement learning (RL) is a popular approach\nfor arriving at optimal strategies by predicating stimuli, such as the reward\nfor following a strategy, on experience. RL is heavily explored in the\nsingle-agent context, but is a nascent concept in multiagent problems. To this\nend, I propose several principled model-free and partially model-based\nreinforcement learning approaches for several multiagent settings. In the realm\nof normative reinforcement learning, I introduce scalable extensions to Monte\nCarlo exploring starts for partially observable Markov Decision Processes\n(POMDP), dubbed MCES-P, where I expand the theory and algorithm to the\nmultiagent setting. I first examine MCES-P with probably approximately correct\n(PAC) bounds in the context of multiagent setting, showing MCESP+PAC holds in\nthe presence of other agents. I then propose a more sample-efficient\nmethodology for antagonistic settings, MCESIP+PAC. For cooperative settings, I\nextend MCES-P to the Multiagent POMDP, dubbed MCESMP+PAC. I then explore the\nuse of reinforcement learning as a methodology in searching for optima in\nrealistic and latent model environments. First, I explore a parameterized\nQ-learning approach in modeling humans learning to reason in an uncertain,\nmultiagent environment. Next, I propose an implementation of MCES-P, along with\nimage segmentation, to create an adaptive team-based reinforcement learning\ntechnique to positively identify the presence of phenotypically-expressed water\nand pathogen stress in crop fields.', 'This paper presents a game, controlled by computer vision, in identification\nof hand gestures (hand-tracking). The proposed work is based on image\nsegmentation and construction of a convex hull with Jarvis Algorithm , and\ndetermination of the pattern based on the extraction of area characteristics in\nthe convex hull.']","['SwipeCut: Interactive Segmentation with Diversified Seed Proposals', 'Optimal Decision-Making in Mixed-Agent Partially Observable Stochastic Environments via Reinforcement Learning', 'Uma implementação do jogo Pedra, Papel e Tesoura utilizando Visao Computacional']","[""['cs.CV']"", ""['cs.LG', 'cs.AI']"", ""['cs.CV']""]","[0.8065434694290161, 0.8056607246398926, 0.804391622543335]",Incorrect,This  question was out of the topics present in data
How can data-driven insights optimize customer support in retail environments?,Using a human-in-the-loop algorithm,By analyzing transaction patterns and customer behavior.,"['What Image Features Boost Housing Market Predictions?', 'MCU-Net: A framework towards uncertainty representations for decision support system patient referrals in healthcare contexts', 'A Fast Fully Octave Convolutional Neural Network for Document Image Segmentation']","[""The attractiveness of a property is one of the most interesting, yet\nchallenging, categories to model. Image characteristics are used to describe\ncertain attributes, and to examine the influence of visual factors on the price\nor timeframe of the listing. In this paper, we propose a set of techniques for\nthe extraction of visual features for efficient numerical inclusion in\nmodern-day predictive algorithms. We discuss techniques such as Shannon's\nentropy, calculating the center of gravity, employing image segmentation, and\nusing Convolutional Neural Networks. After comparing these techniques as\napplied to a set of property-related images (indoor, outdoor, and satellite),\nwe conclude the following: (i) the entropy is the most efficient single-digit\nvisual measure for housing price prediction; (ii) image segmentation is the\nmost important visual feature for the prediction of housing lifespan; and (iii)\ndeep image features can be used to quantify interior characteristics and\ncontribute to captivation modeling. The set of 40 image features selected here\ncarries a significant amount of predictive power and outperforms some of the\nstrongest metadata predictors. Without any need to replace a human expert in a\nreal-estate appraisal process, we conclude that the techniques presented in\nthis paper can efficiently describe visible characteristics, thus introducing\nperceived attractiveness as a quantitative measure into the predictive modeling\nof housing."", 'Incorporating a human-in-the-loop system when deploying automated decision\nsupport is critical in healthcare contexts to create trust, as well as provide\nreliable performance on a patient-to-patient basis. Deep learning methods while\nhaving high performance, do not allow for this patient-centered approach due to\nthe lack of uncertainty representation. Thus, we present a framework of\nuncertainty representation evaluated for medical image segmentation, using\nMCU-Net which combines a U-Net with Monte Carlo Dropout, evaluated with four\ndifferent uncertainty metrics. The framework augments this by adding a\nhuman-in-the-loop aspect based on an uncertainty threshold for automated\nreferral of uncertain cases to a medical professional. We demonstrate that\nMCU-Net combined with epistemic uncertainty and an uncertainty threshold tuned\nfor this application maximizes automated performance on an individual patient\nlevel, yet refers truly uncertain cases. This is a step towards uncertainty\nrepresentations when deploying machine learning based decision support in\nhealthcare settings.', 'The Know Your Customer (KYC) and Anti Money Laundering (AML) are worldwide\npractices to online customer identification based on personal identification\ndocuments, similarity and liveness checking, and proof of address. To answer\nthe basic regulation question: are you whom you say you are? The customer needs\nto upload valid identification documents (ID). This task imposes some\ncomputational challenges since these documents are diverse, may present\ndifferent and complex backgrounds, some occlusion, partial rotation, poor\nquality, or damage. Advanced text and document segmentation algorithms were\nused to process the ID images. In this context, we investigated a method based\non U-Net to detect the document edges and text regions in ID images. Besides\nthe promising results on image segmentation, the U-Net based approach is\ncomputationally expensive for a real application, since the image segmentation\nis a customer device task. We propose a model optimization based on Octave\nConvolutions to qualify the method to situations where storage, processing, and\ntime resources are limited, such as in mobile and robotic applications. We\nconducted the evaluation experiments in two new datasets CDPhotoDataset and\nDTDDataset, which are composed of real ID images of Brazilian documents. Our\nresults showed that the proposed models are efficient to document segmentation\ntasks and portable.']","[""['cs.CV', 'cs.LG']"", ""['cs.LG', 'cs.CV', 'stat.ML']"", ""['cs.CV', 'eess.IV']""]","[0.8304593563079834, 0.8281747102737427, 0.8260115385055542]",Incorrect,This  question was out of the topics present in data
